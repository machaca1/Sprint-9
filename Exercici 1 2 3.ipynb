{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "498a7b85",
   "metadata": {},
   "source": [
    "Calcula la frecuencia de palabras utilizando NLTK.\n",
    "Treu les stopwords i realitza stemming al teu conjunt de dades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c227cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('data', 7), ('experi', 6), ('manag', 5), ('mindfuel', 4), ('skill', 4), ('team', 4), ('product', 3), ('posit', 3), ('work', 3), ('project', 3)]\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "with open('Cover_letter.pdf', 'rb') as pdf_file:\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    num_pages = len(pdf_reader.pages)\n",
    "\n",
    "    text = ''\n",
    "    for page_num in range(num_pages):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        text += page.extract_text()\n",
    "\n",
    "tokens = word_tokenize(text.lower())\n",
    "\n",
    "filtered_tokens = [stemmer.stem(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "freq_dist = FreqDist(filtered_tokens)\n",
    "\n",
    "print(freq_dist.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c45adc",
   "metadata": {},
   "source": [
    "Realitza sentiment analysis al teu conjunt de dades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3bf37b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.783, 'pos': 0.217, 'compound': 0.996}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "scores = analyzer.polarity_scores(text)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e697b05",
   "metadata": {},
   "source": [
    "La puntuación de sentimiento en mi carta de presentación indica lo siguiente:\n",
    "\n",
    "    'neg': 0.0: No se detectó ningún sentimiento negativo en el texto.\n",
    "    'neu': 0.783: El texto es principalmente neutral, lo que significa que no hay una inclinación clara hacia un sentimiento en particular.\n",
    "    'pos': 0.217: Hay una pequeña inclinación positiva en el texto.\n",
    "    'compound': 0.996: El puntaje compuesto es muy alto, lo que indica que en general el texto tiene una tendencia muy positiva.\n",
    "\n",
    "En resumen, la puntuación sugiere que mi carta de presentación es principalmente neutral con una leve inclinación positiva y un tono general muy positivo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
